
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Aubade_Blog</title>
        <meta name="author" content="Terrance">
        <meta name="description" content="Persisting will immortalizes freedom.">
        <meta name="keywords" content="">
        <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0">
        <link rel="icon" href="/images/OIP.jpg">
        <script src="https://cdn.staticfile.org/vue/3.2.45/vue.global.prod.min.js"></script>
        <script src="https://cdn.staticfile.org/highlight.js/11.7.0/highlight.min.js"></script>
        <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/11.7.0/styles/github.min.css">
        <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/6.2.1/css/all.min.css">
        
        <script src="https://polyfill.io/v3/polyfill.min.js?features=default"></script>
        
        
        <script src="https://cdn.staticfile.org/KaTeX/0.16.4/katex.min.js"></script>
        <script src="https://cdn.staticfile.org/KaTeX/0.16.4/contrib/auto-render.min.js"></script>
        <link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.16.4/katex.min.css">
        
        
        <link rel="stylesheet" href="/css/fonts.min.css">
        <link rel="stylesheet" href="/css/particlex.css">
    <meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <div id="loading" style="height: 100vh; width: 100vw; left: 0; top: 0; position: fixed; display: flex; z-index: 2147483647; background: #fff; transition: opacity 0.3s ease-out; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; pointer-events: none">
    <div style="width: 50vmin; height: 50vmin; margin: auto; padding: 50px; border-radius: 50%; display: flex; border: solid 10px #a3ddfb">
        <div style="margin: auto; text-align: center">
            <h2>LOADING</h2>
            <p>加载过慢请开启缓存，浏览器默认开启</p>
            <img src="/images/loading.gif" style="height: 50px; border-radius: 0">
        </div>
    </div>
</div>

        <div id="layout">
            <transition name="into">
            <div id="main" v-show="showpage" style="display: -not-none">
                <nav id="menu">
    <div class="desktop-menu">
        <a class="title" href="/">
            <span>AUBADE_BLOG</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </div>
    <div :class="&quot;phone-menu &quot; + menushow" id="phone-menu">
        <div class="curtain" @click="menushow = !menushow" v-show="menushow"></div>
        <div class="title" @click="menushow = !menushow">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;AUBADE_BLOG</span>
        </div>
        <transition name="slide">
        <div class="items" v-show="menushow">
            
            <a href="/">
                <div class="item">
                    <div style="min-width: 20px; max-width: 50px; width: 10%">
                        <i class="fa-solid fa-house fa-fw"></i>
                    </div>
                    <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                </div>
            </a>
            
            <a href="/about">
                <div class="item">
                    <div style="min-width: 20px; max-width: 50px; width: 10%">
                        <i class="fa-solid fa-id-card fa-fw"></i>
                    </div>
                    <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                </div>
            </a>
            
            <a href="/archives">
                <div class="item">
                    <div style="min-width: 20px; max-width: 50px; width: 10%">
                        <i class="fa-solid fa-box-archive fa-fw"></i>
                    </div>
                    <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                </div>
            </a>
            
            <a href="/categories">
                <div class="item">
                    <div style="min-width: 20px; max-width: 50px; width: 10%">
                        <i class="fa-solid fa-bookmark fa-fw"></i>
                    </div>
                    <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                </div>
            </a>
            
            <a href="/tags">
                <div class="item">
                    <div style="min-width: 20px; max-width: 50px; width: 10%">
                        <i class="fa-solid fa-tags fa-fw"></i>
                    </div>
                    <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                </div>
            </a>
            
        </div>
        </transition>
    </div>
</nav>

                <div id="home-head">
    <div id="home-background" style="background-image: url(/images/bk.jfif)"></div>
    
    <div id="home-info" @click="homeclick">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>Aubade_Blog</h1>
                <h3></h3>
                <h5>Persisting will immortalizes freedom.</h5>
            </div>
        </span>
    </div>
    
</div>
<div id="home-posts-wrap" class="">
    <div id="home-posts">
        <div id="posts">
            

<div class="post">
    <a href="/2023/04/01/Handling-Crashes-and-Performance/">
        <h2 class="post-title">Handling Crashes and Performance</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP-310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP 310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/4/1
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="RAID"><a href="#RAID" class="headerlink" title="RAID"></a>RAID</h2><p>RAID is used for combining many disks, for: Capacity, Reliability, Performance<br>Challange: Most FS work with one disk</p>
<h3 id="Building-Multiple-Disks"><a href="#Building-Multiple-Disks" class="headerlink" title="Building Multiple Disks"></a>Building Multiple Disks</h3><h4 id="Approaches"><a href="#Approaches" class="headerlink" title="Approaches"></a>Approaches</h4><h5 id="JBOD-just-a-bunch-of-disks"><a href="#JBOD-just-a-bunch-of-disks" class="headerlink" title="JBOD (just a bunch of disks)"></a>JBOD (just a bunch of disks)</h5><p>If the application is smart, it can stores different files on different file systems.</p>
<h5 id="RAID-Redundant-Array-of-Independent-Disks"><a href="#RAID-Redundant-Array-of-Independent-Disks" class="headerlink" title="RAID(Redundant Array of Independent Disks)"></a>RAID(Redundant Array of Independent Disks)</h5><p>Create the illusion of one disk from many disks.<br>The core is to use fake logical disk.<br><img src="/.com//1.png"></p>
<p><strong>Essential Idea</strong></p>
<ul>
<li>Optimize I&#x2F;O bandwidth through parallel I&#x2F;O</li>
<li>Parallel I&#x2F;O &#x3D; I&#x2F;O to multiple disks at once</li>
</ul>
<p><strong>Strategies</strong></p>
<ul>
<li>Mapping</li>
<li>Redundancy</li>
</ul>
<h6 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h6><p>Provides an illusion that multiple disks behave as one.<br><img src="/.com//2.png"></p>
<p><strong>Striping</strong><br>Striping is a form of mapping. It put file across several disks : File &#x3D; Stripe0 | Stripe1 | Stripe2 …</p>
<p><strong>RAID-0 : No Redundancy</strong></p>
<ul>
<li>Uses Striping</li>
<li>Best possible read and write bandwidth</li>
<li>Failure results in data loss -&gt; If one of the disks get crashed, then file may loss</li>
<li>More disks increase throughput but not latency</li>
</ul>
<blockquote>
<p>Latency: How fast we can do a request<br>Throughput: How many request can one do in a unit time</p>
</blockquote>
<h6 id="Redundancy"><a href="#Redundancy" class="headerlink" title="Redundancy"></a>Redundancy</h6><p>Redundancy is leading in to solve the problem of tolerance to disk failure.<br>The core idea is: store redundant data on different disks<br><em>it’s an improvement based on mapping</em><br><img src="/.com//3.png"></p>
<p><strong>RAID-1 : Mirroring</strong><br><img src="/.com//41.png"><br>Mirroring does not only increase the tolerance to disk failure, but also boost the efficiency for reading.</p>
<ul>
<li>Storage capacity is half of the whole disk</li>
</ul>
<p><strong>RAID-4 : Parity Disk</strong><br>N data disks + 1 Parity Disk<br><img src="/.com//42.png"><br><u>Parity</u>:</p>
<ul>
<li>A simple form of error detection and repair</li>
<li>Not specific to RAID</li>
<li>Also used in communications</li>
</ul>
<p><u>Parity Updates</u>:<br>Each time when we write to the disk we need to update the parity.  </p>
<ul>
<li>Additive Parity &#x3D; Read all other datablocks in parallel and XOR them with the new block</li>
<li>Subtractive Parity <ul>
<li>Read old data and parity in parallel</li>
<li>compare new data with old data</li>
<li>if new data &#x3D;&#x3D; old data -&gt; do nothing</li>
<li>else, flip old parity bit</li>
</ul>
</li>
</ul>
<blockquote>
<p>RAID-4 requires access to parity disk for each write, this cause bottleneck in write-heavy workload.<br>Parallelism in data disks puts time lag on parity disk<br>The issue is called  <strong>small-write problem</strong></p>
</blockquote>
<p><strong>RAID-5 : Distributed Parity</strong><br><img src="/.com//43.png"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #00bcd4">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Notes/" style="color: #00bcd4">
                Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/04/01/Handling-Crashes-and-Performance/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/30/COMP310-Advanced-FS-LogStructureDesigns/">
        <h2 class="post-title">COMP310-Advanced FS-LogStructureDesigns</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310-Lecture-Notes/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310, Lecture Notes
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h1 id="Advanced-FS-Log-Structured-Designs"><a href="#Advanced-FS-Log-Structured-Designs" class="headerlink" title="Advanced FS: Log-Structured Designs"></a>Advanced FS: Log-Structured Designs</h1><p><strong>Key Concepts</strong></p>
<ul>
<li>Log-Structure File System</li>
<li>Log-Structure Key-Value Store</li>
</ul>
<p><strong>Reason</strong><br>Dealing with Crashes:<br>If the crash happens at the point in the middle of the data, thenn it will be a problem since <strong>the os doesn’t know which part is the new data and which part is the old data</strong>.<br>For <strong>write-behind</strong>, the crash may be a problem also even after finished since the file may not be transffered.</p>
<h2 id="Handling-Crash"><a href="#Handling-Crash" class="headerlink" title="Handling Crash"></a>Handling Crash</h2><p><strong>Crash</strong>: a situation which the operation of the application errs, stopping its functionality.</p>
<h3 id="Solution-Atomicity"><a href="#Solution-Atomicity" class="headerlink" title="Solution: Atomicity"></a>Solution: Atomicity</h3><h4 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h4><p><strong>Assumption</strong>:</p>
<ol>
<li>A single sector disk write is atomic<br><em>The assumption is true with very high probability(YES)</em><br><strong>Approach</strong>:</li>
<li>Shadow Paging</li>
<li>Intentions Log</li>
</ol>
<h5 id="Shadow-Paging"><a href="#Shadow-Paging" class="headerlink" title="Shadow Paging"></a>Shadow Paging</h5><ul>
<li>Make sure both old copy and new copy are on the disk.</li>
<li>Make atomic switch between the two &#x3D;&gt; By doing a <code>WriteSecor()</code><ul>
<li>The atomic change must be done on inode since it’s smaller than sector, so we write in inode entry</li>
</ul>
</li>
</ul>
<p><strong>Step(Write Through)</strong>:<br><img src="/.com//00.png"><br><img src="/.com//0.png"><br>We first write new data blocks on the disk -&gt; after each writing, we update the inode in memory pointing to the new block -&gt; After the update is done in cache, we use atomic writesector() -&gt; Start garbage collection to clean the old data blocks</p>
<p><strong>Step(Write Behind)</strong>:<br><img src="/.com//11.png"><br>The difference to write-through is that the data will not be directly write to the disk, instead, they will be write to the memory first then transfer to the disk. The block space will be allocated first for the disk before transferrence.<br><img src="/.com//12.png"><br>The step of transferring the block to the disk is not atomic.<br><em>(If failed, we may still recover the old version of the file)</em> &lt;- <em>Notice that the old blocks are not collected as the garbage yet</em><br><img src="/.com//14.png"><br>But for the <code>WriteSector()</code> instruction, it is atomic.<br><img src="/.com//13.png"><br>The old blocks will be cleaned finally.</p>
<blockquote>
<p>The OS will de-allocate the data blocks; if the OS crashes before de-allocation, FS will check.</p>
</blockquote>
<h5 id="Intentions-Log"><a href="#Intentions-Log" class="headerlink" title="Intentions Log"></a>Intentions Log</h5><p><strong>Log</strong>: Special area on disk which can only be appended instead of being overwritten</p>
<p>Log itself acts as an intermediate media for transferrance between cache and disk.</p>
<p><img src="/.com//21.png"><br><img src="/.com//22.png"><br><img src="/.com//23.png"><br><img src="/.com//24.png"><br><img src="/.com//25.png"><br>The log will still be checked if the old data is there.<br>The log will be garbage collected after all the instructions are finished.</p>
<h5 id="Comparision-which-one-is-better"><a href="#Comparision-which-one-is-better" class="headerlink" title="Comparision: which one is better"></a>Comparision: which one is better</h5><p><strong>Criterion</strong></p>
<ul>
<li>The number of disk I&#x2F;O</li>
<li>the number of random disk I&#x2F;O<br><img src="/.com//31.png"><br><em>It’s true theoratically that the shadow paging takes less operations; however, intention log works better.</em></li>
</ul>
<p><img src="/.com//32.png"><br>Log works better mainly because accession in log is sequential, and there’s less data fragmentation inside the log compared to the shadow paging. Shawdow paging requires jumping around facing accession, but log does not.</p>
<h2 id="Log-structured-File-System-LFS"><a href="#Log-structured-File-System-LFS" class="headerlink" title="Log-structured File System(LFS)"></a>Log-structured File System(LFS)</h2><ul>
<li>Alternative way of structuring file system</li>
<li>Log &#x3D; append-only data structure(on disk)</li>
</ul>
<p> <strong>Idea</strong>: Use the disk purely sequentially</p>
<ul>
<li>Good for writing due to the sequential property</li>
<li>Bad for reading since may read from spacing sectors</li>
</ul>
<h3 id="Strategy"><a href="#Strategy" class="headerlink" title="Strategy"></a>Strategy</h3><p><img src="/.com//41.png"></p>
<h3 id="Data-Structures"><a href="#Data-Structures" class="headerlink" title="Data Structures"></a>Data Structures</h3><p>We store all the information including both data blocks and inodes to the log, which causes the problem of distinguishing between them. This need to be solved by using specific data structure.</p>
<h4 id="Naive-Idea"><a href="#Naive-Idea" class="headerlink" title="Naive Idea:"></a>Naive Idea:</h4><ul>
<li>Use current offset on disk instead of table index for uid</li>
<li>When update inode, inode number changes</li>
</ul>
<p><img src="/.com//51.png"><br><img src="/.com//52.png"><br><em>Because the log can only append</em></p>
<h4 id="Better-Idea"><a href="#Better-Idea" class="headerlink" title="Better Idea:"></a>Better Idea:</h4><ul>
<li>Add a level of indirection<ul>
<li>Map: file uid -&gt; inode location on disk</li>
<li>Data structure is called Imap(Inode map)<br><img src="/.com//61.png"><br><img src="/.com//62.png"></li>
</ul>
</li>
</ul>
<h3 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h3><hr>
<h2 id="Log-structure-key-value-stores"><a href="#Log-structure-key-value-stores" class="headerlink" title="Log-structure key value stores"></a>Log-structure key value stores</h2><p><strong>Key-Value Stores(KVs)</strong><br>Crucial component in systems with large amounts of diverse data, unstructured data.<br><img src="/.com//201.png"><br><strong>Log-structured key value stores</strong><br><img src="/.com//202.png"></p>
<h3 id="LSM-KVs-Intervals"><a href="#LSM-KVs-Intervals" class="headerlink" title="LSM KVs Intervals"></a>LSM KVs Intervals</h3><p><img src="/.com//211.png"></p>
<ul>
<li>Commit log is a datastructure used to backup the info in Memory to the disk</li>
<li>Commit log is optional and can be turned off(makes the transmission faster)</li>
<li>Memory Sorted Buffer is any data structure preserving the order</li>
</ul>
<p><strong>LSM Writing</strong><br>Each time the client write something to the memory, if the commit log is on, OS will automatically transfer the info to the commit log.<br><img src="/.com//212.png"><br>When the buffer is full, we write the old one from the memory to disk sequentially, creating one sorted immutable files. -&gt; Then we empty the write buffer and the commit log.<br><img src="/.com//213.png"></p>
<p><strong>LSM Reading</strong><br><img src="/.com//221.png"><br>The above hierarchy is not the actual separation, instead, they are logical hierarchy. </p>
<ul>
<li>L0 is reserved for flushing memory component to disk (Special since multiple version of the file can be in L0 at the same time)</li>
<li>Starting from L1 (to Ln), each key in the key space can exist in only one of the files, which is guarantee by the key value store.</li>
<li>The oldest version is in the lowest level, newest is in the highest level.</li>
</ul>
<blockquote>
<p>L0 can contain many files with the same K, but L1 - Ln only contain one file with its own key</p>
</blockquote>
<blockquote>
<p>one Key k can correspond to multiple files in different level and we only want the latest version.<br> Read from memory &#x3D;(not in memory)&#x3D;&gt; Read from Block cache &#x3D;(not in cache)&#x3D;&gt;Sequentially iterates through L0 to Ln<br><img src="/.com//222.png"><br>The log-structured key value stores is optimizaed for writing but not reading</p>
</blockquote>
<blockquote>
<p>Each file contains a range of the key, so we can determine where does the key reside. In L0, the range of the file is not distinguished.</p>
</blockquote>
<p><strong>LSM Internal Operations</strong></p>
<p><img src="/.com//230.png"></p>
<h4 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h4><p><img src="/.com//231.png"><br><img src="/.com//241.png"><br>Ideal WA &#x3D; 1<br><img src="/.com//242.png"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310-Lecture-Notes/" style="color: #ffa2c4">
                COMP310, Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/03/30/COMP310-Advanced-FS-LogStructureDesigns/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/28/Persistent-Storage-Basic-File-System-Implementation/">
        <h2 class="post-title">Persistent Storage:Basic File System Implementation</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/28
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>Different file system can have different implementations, but they have essential common triats.</p>
<p>File System: Creating a mapping between files(a sequence of uninterrupted untyped byte) and blocks on storage device. <em>(Block itself is another abstraction to the storage device)</em></p>
<h3 id="File-System-Role"><a href="#File-System-Role" class="headerlink" title="File System Role"></a>File System Role</h3><p>The main task of file system is to translate : from <strong>user interface</strong> functions to <strong>disk interface</strong> fucntions.</p>
<h2 id="File-System-Implementation"><a href="#File-System-Implementation" class="headerlink" title="File System Implementation"></a>File System Implementation</h2><p><strong>Key aspects</strong>:</p>
<ul>
<li>Data Structures : data structures on disk and data structures in memory</li>
<li>Access methods</li>
</ul>
<blockquote>
<p>Data structure must be on disk since disk is involatile. The metadata needed by the OS for mapping also must be on disk.</p>
</blockquote>
<h3 id="Disk-Data-Structures"><a href="#Disk-Data-Structures" class="headerlink" title="Disk Data Structures"></a>Disk Data Structures</h3><ul>
<li>Data Region(actual information) -&gt; occupies most space in FS<ul>
<li>User data</li>
<li>free space</li>
</ul>
</li>
<li>Meta data<ul>
<li>Indicates the specific space used for user data and free space(Inode)</li>
<li>house keeping stuff</li>
</ul>
</li>
</ul>
<p>We use metadata to track files, specifically, by the inode of the metadata.<br><img src="/.com//0.png" alt="example"></p>
<p><strong>Structure Implementation</strong></p>
<ul>
<li>Free-list</li>
<li>Bitmaps<ul>
<li>Data structure where each bit indicates if corresponding object is free or in use</li>
<li>1 &#x3D; in use ; 0 &#x3D; free </li>
<li>we associate each block to a bit in bitmap</li>
<li>We have inode bitmap and data bitmap<br><img src="/.com//1.png" alt="Bitmap Capacity"><br><img src="/.com//2.png" alt="Structure"><br>Superblock is the block used to track the metadata.</li>
</ul>
</li>
</ul>
<h3 id="Allocation-of-files-to-blocks"><a href="#Allocation-of-files-to-blocks" class="headerlink" title="Allocation of files to blocks"></a>Allocation of files to blocks</h3><p>Based on inode.<br><strong>Criteria for good strategy</strong></p>
<ul>
<li>Amount of fragmentation (external and internal)</li>
<li>Ability to grow file over time</li>
<li>Sequential access performance</li>
<li>Random access performance</li>
<li>Metadata overhead</li>
</ul>
<h4 id="Strategy"><a href="#Strategy" class="headerlink" title="Strategy:"></a>Strategy:</h4><p><strong>Contiguous allocation</strong></p>
<ul>
<li>Strategy: Allocate file data blocks contiguously on disk</li>
<li>Metadata: Starting block + size of file</li>
<li>Fragmentation: severe external frgamentation</li>
<li>Growing: may be time intense</li>
<li>Sequential access: good</li>
<li>Random access: good</li>
<li>Metadata overhead: low since just two number needs for matadata<br>The only case to use this is of the read-only.<br>Impractical for file system since it change files alot.<br><img src="/.com//30.png" alt="Contiguous allocation"></li>
</ul>
<p><strong>Extent-based allocation</strong><br>Trying to take advantage of the fragmentation but get rid of the holes.</p>
<ul>
<li>Stratgey: Allocate multiple contiguous extent per file.<br><img src="/.com//31.png" alt="Extent-based allocation"></li>
</ul>
<p><strong>Linked-List Allocation</strong><br>Each block likes a node in the linked list.</p>
<ul>
<li>Strategy: Allocate linked-list of blocks.</li>
<li>Metadata: Location of first block of file, plus each block contains pointer to next block.<br><img src="/.com//32.png" alt="Linked-list allocation"></li>
</ul>
<p><strong>FAT(File-Allocation Tables)</strong><br>Exactly like the linked list with the difference that pointers are store in a different data structure.<br>Pointers are stored in FAT.<br><img src="/.com//33.png" alt="FAT allocation"><br>Since Table can be stored in cache, the accession time dies down.</p>
<p><strong>Index Allocation</strong><br><img src="/.com//34.png" alt="Index allocation"></p>
<p><strong>Index Allocation with Indirect Blocks</strong><br><img src="/.com//35.png" alt="IIB allocation"><br>Support Large files.<br><img src="/.com//37.png" alt="IIB allocation"><br>slower since an indirect node is leading in, 2 times slower. 4 more blocks.</p>
<blockquote>
<p>Directory stores as files.</p>
</blockquote>
<p>If the file size is larger than the size that inode can represent, then the open will fail.</p>
<hr>
<h3 id="Operations-of-data-stuctures-on-disk"><a href="#Operations-of-data-stuctures-on-disk" class="headerlink" title="Operations of data stuctures on disk"></a>Operations of data stuctures on disk</h3><p>Inefficient.</p>
<p><img src="/.com//40.png" alt="Create /foo/bar"><br>If a new file is created, there’s no content in it, only inode of that file will be created.</p>
<p><img src="/.com//41.png" alt="Open /foo/bar"></p>
<p><img src="/.com//42.png" alt="Write /foo/bar"><br>Open it before write. The above graph omits the steps for openning the file.</p>
<p><img src="/.com//43.png" alt="Read /foo/bar"><br>Open it before read. The above graph omits the steps for openning the file.</p>
<p><img src="/.com//44.png" alt="Close /foo/bar"></p>
<h3 id="Operations-of-data-stuctures-in-memory"><a href="#Operations-of-data-stuctures-in-memory" class="headerlink" title="Operations of data stuctures in memory"></a>Operations of data stuctures in memory</h3><h4 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h4><ul>
<li>Finxed contiguous area of kernel memory.</li>
<li>Size &#x3D; max number of chache blocks x block size</li>
<li>A large chunck pf memeory of the machine</li>
<li>In general, write behind is used</li>
<li>For user data is OK</li>
<li>For metadata, depends</li>
</ul>
<h4 id="Cache-Directory"><a href="#Cache-Directory" class="headerlink" title="Cache Directory"></a>Cache Directory</h4><p>index in the cache pointing to the disk data (usually hash table)<br><img src="/.com//45.png" alt="LRU"></p>
<p><img src="/.com//46.png" alt="Cache Flush"></p>
<h4 id="System-Wide-Active-File-Table"><a href="#System-Wide-Active-File-Table" class="headerlink" title="(System-Wide) Active File Table"></a>(System-Wide) Active File Table</h4><p>Indicates what files are in use in the system. </p>
<ul>
<li>One array for the entire system</li>
<li>One entry per onpen file</li>
<li>Each entry contains<ul>
<li>file inode</li>
<li>Additional Information<ul>
<li>Reference count of number of file opens</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Per-Process-Open-File-Table"><a href="#Per-Process-Open-File-Table" class="headerlink" title="(Per-Process) Open File Table"></a>(Per-Process) Open File Table</h4><ul>
<li>One array per process</li>
<li>One entry per file open of that process</li>
<li>Indexed by file descriptor $fd$</li>
<li>Each entry contains<ul>
<li>Pointer to file inode in active file table</li>
<li>File pointer $fp$</li>
<li>Additional Information</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Open File Table</strong> and <strong>Active File Table</strong> are put together in use.<br><strong>Open File Table</strong> is in the perspective of the process(PCB); <strong>Active File Table</strong> is in the perspective of the kernel.</p>
</blockquote>
<blockquote>
<p><strong>UID</strong> is a component of the <strong>inode</strong>.</p>
</blockquote>
<blockquote>
<p>The two tables are combined instead of singally use is because of the <strong>concurrency</strong>. We wish the process can access to the file concurrently.</p>
</blockquote>
<h3 id="Combination-of-Memory-Structure-with-Disk-Structure"><a href="#Combination-of-Memory-Structure-with-Disk-Structure" class="headerlink" title="Combination of Memory Structure with Disk Structure"></a>Combination of Memory Structure with Disk Structure</h3><p><img src="/.com//60.png" alt="CREATE"><br>Most of the times, data bitmap and inode bitmap are in chache,even some specific inode.<br>If the data(info) is already cached, there’s no need to read again.</p>
<p><img src="/.com//61.png" alt="OPEN"></p>
<p><img src="/.com//62.png" alt="WRITE"></p>
<p><img src="/.com//63.png" alt="read"></p>
<p><img src="/.com//64.png" alt="close"></p>
<h3 id="Setting-up-the-FS"><a href="#Setting-up-the-FS" class="headerlink" title="Setting up the FS"></a>Setting up the FS</h3><ul>
<li>By default, OS sees all storage devices as<ul>
<li>Chunks of unallocated space</li>
<li>which are unusable</li>
</ul>
</li>
<li>Cannot start writing file to a blank drive</li>
<li>Need to set up the FS first(Disk Parititioning)</li>
</ul>
<h4 id="Disk-Partition-Slicing"><a href="#Disk-Partition-Slicing" class="headerlink" title="Disk Partition(Slicing)"></a>Disk Partition(Slicing)</h4><ul>
<li>FS needs a “container”(partition) on the storage device</li>
<li>Partition allows different FS to be installed on same OS.</li>
<li>Each partition appears to OS as a logical disk</li>
<li>Disk stores partition info in partition table</li>
<li>OS reads partition table before anyother parts of the disk</li>
</ul>
<h4 id="Mounting-a-FS"><a href="#Mounting-a-FS" class="headerlink" title="Mounting a FS"></a>Mounting a FS</h4><p>FS needs to be mounted for OS to acces its files.(Make OS know where the file system is).</p>
<ul>
<li>Mounting attaches FS to a directory</li>
<li>Directory is called mount point</li>
</ul>
<p>All the file systems would be attached to a root file system.</p>
<blockquote>
<p>Mounting does not delete the files under the mount point; it only makes the file system can’t see the files.<br>If we unmount, the appearance goes to initial state.</p>
</blockquote>
<h4 id="Booting"><a href="#Booting" class="headerlink" title="Booting"></a>Booting</h4><ul>
<li>BIOS lookes for clues on what it needs to start OS. BIOS checkes <strong>boot block</strong> first.</li>
<li>A fixed location on disk (usually sector 0), containing boot loader and partition table.</li>
<li>Read by BIOS on machine boot.</li>
</ul>
<h3 id="Alternative-File-Access-Method-Memory-Mapping"><a href="#Alternative-File-Access-Method-Memory-Mapping" class="headerlink" title="Alternative File Access Method: Memory Mapping"></a>Alternative File Access Method: Memory Mapping</h3><p>Memory mapping: a way to not use the file system.</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
    </div>
    <a href="/2023/03/28/Persistent-Storage-Basic-File-System-Implementation/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/25/COMP310-Intro-to-FileSystems/">
        <h2 class="post-title">COMP310-Intro-to-FileSystems</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/25
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>OS &#x3D; Process Management + Memory Management + File System + I&#x2F;O</p>
<h2 id="I-x2F-O-Devices"><a href="#I-x2F-O-Devices" class="headerlink" title="I&#x2F;O Devices"></a>I&#x2F;O Devices</h2><p><img src="/.com//0.png" alt="I/O System Architecture"><br><strong>Buses Type</strong>:  </p>
<ul>
<li>PCIE (peripheral component interconnect express)<ul>
<li>PCIE is often used to connect to high performance devices</li>
</ul>
</li>
<li>DMI (Direct media interface)</li>
<li>USB (Universal serial bus)</li>
<li>eSATA (external SATA)<ul>
<li>SATA (Serial ATA)</li>
<li>ATA (the AT attachment, in reference to providing connection to the IBM PC AT)<blockquote>
<p><strong>Reason for the classification(architecture)</strong>  </p>
<ol>
<li>Physical significance<br>  Higher performance devices connected via high performance buses(wider and shorter)</li>
<li>To put a large number of devices into the system</li>
</ol>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="How-does-OS-communicate-with-I-x2F-O-devices"><a href="#How-does-OS-communicate-with-I-x2F-O-devices" class="headerlink" title="How does OS communicate with I&#x2F;O devices?"></a>How does OS communicate with I&#x2F;O devices?</h3><p>By <strong>Canonical Device Interface</strong>.<br><strong>Canonical Device Interface</strong>:<br>Interface made of 3 registers:</p>
<ul>
<li>Status - current status of device</li>
<li>Command - OS tells device what command to perform</li>
<li>Data - send&#x2F;receive data from device</li>
</ul>
<p><em>OS alters the registers to communicate with IO&#x2F;O devices</em></p>
<p><img src="/.com//1.png" alt="CDI(Canonical Device Interface)"><br>All the hidden internals are visible to the hardware but invisible to the OS.</p>
<h4 id="How-does-OS-use-device-interface"><a href="#How-does-OS-use-device-interface" class="headerlink" title="How does OS use device interface?"></a>How does OS use device interface?</h4><ul>
<li><p>DMA</p>
</li>
<li><p>Polling<br>OS waits untile the device is ready. Repeatedly checks the STATUS of the registers in a loop.  </p>
<ul>
<li>Pro: simple</li>
<li>Con: Wasted CPU cycles</li>
</ul>
</li>
<li><p>Interrupt<br>Put process requesting I&#x2F;O to <strong>sleep</strong>. -&gt; <strong>Context switch</strong> to a different process. -&gt; When I&#x2F;O finishes, wake sleeping process with an <strong>interrupt</strong>. -&gt; CPU jumps to <strong>Interrupt Handler</strong> in the OS. -&gt; wake up A</p>
<ul>
<li>Pro: no waste of CPU cycles</li>
<li>Con: expensive context switch (polling can be better for fast devices since $T(I&#x2F;O)&lt;T(context switch)$)<blockquote>
<ol>
<li>Same mechanism is used for demand paging</li>
<li>A is waken up by <strong>interrupt handler</strong></li>
</ol>
</blockquote>
</li>
</ul>
<blockquote>
<p>NOTICE: <strong>Interrupt</strong> is generated by the hardware to initiate a context switch(switching between user and kernel mode). <strong>Syscall</strong> is generated by the process to request functionality from kernel mode, also initiates a context switch(switching between user and kernel mode). <strong>Trap</strong> goes from user space to kernel space.</p>
</blockquote>
</li>
</ul>
<h3 id="How-to-handle-different-devices-in-OS"><a href="#How-to-handle-different-devices-in-OS" class="headerlink" title="How to handle different devices in OS?"></a>How to handle different devices in OS?</h3><p>The problem is that each device may have its own protocol(The interface is specific).</p>
<p><strong>Solution: Abstraction</strong>:<br>Adding a layer of abstraction between OS and devices: device driver.</p>
<ul>
<li>Device driver creates a connection between each device and the OS.</li>
<li>Each device needs its own driver</li>
<li>Device driver is a piece of software in OS</li>
</ul>
<p><img src="/.com//3.png"></p>
<h2 id="Permanent-Storage"><a href="#Permanent-Storage" class="headerlink" title="Permanent Storage"></a>Permanent Storage</h2><ul>
<li>Permanent across machine failures&#x2F;restarts</li>
<li>Permanent across disk failures</li>
</ul>
<p><strong>Permanent Storage Media</strong>:<br>Flash SSD, HDD, …</p>
<h3 id="File-System-API"><a href="#File-System-API" class="headerlink" title="File System API"></a>File System API</h3><h4 id="FILE"><a href="#FILE" class="headerlink" title="FILE"></a>FILE</h4><ul>
<li>An un-intepreted collection of objects composed of bytes, records,etc.<ul>
<li>un-intepreted: File system does not know the meaning of the data; only application does</li>
</ul>
</li>
</ul>
<p><strong>Type</strong>:<br>Typed &#x3D; File System knows what the object means<br><em>(Sometimes, the file type is distinguiished by file extensions but it actually depends on the OS itself: UNIX ignore the extension, Windows does not ignore)</em></p>
<ul>
<li>Pro: prevent errors; efficient storage</li>
<li>Con: inflexible; lot of code</li>
</ul>
<blockquote>
<p>We only look <strong>untyped</strong> files in this course</p>
</blockquote>
<h3 id="File-System-Primitives"><a href="#File-System-Primitives" class="headerlink" title="File System Primitives"></a>File System Primitives</h3><p><strong>Checking the lecture</strong></p>
<ul>
<li>Access</li>
<li>Concurrency</li>
<li>Naming</li>
<li>Protection</li>
</ul>
<h4 id="ACCESS"><a href="#ACCESS" class="headerlink" title="ACCESS"></a>ACCESS</h4><p><strong>Sequential &amp; Random Access</strong>  </p>
<ul>
<li>Sequential:<br>A portion of the file is read in order. If the read(write) is suspended and restart, it will continue at the last suspension point.</li>
<li>Random:<br>No connection between accesses in different times.</li>
</ul>
<blockquote>
<p>Read() itself is random access but we can use file pointer to convert it into sequential access.</p>
</blockquote>
<blockquote>
<p>Sequential access is very common and all OS provide it. Not all OS provide random access.(but they may provide seek())</p>
</blockquote>
<h4 id="CONCURRENCY-concueerent-sequential-access"><a href="#CONCURRENCY-concueerent-sequential-access" class="headerlink" title="CONCURRENCY(concueerent sequential access)"></a>CONCURRENCY(concueerent sequential access)</h4><p>Two processes access the same file.<br>Use <code>Open()</code> and <code>Close()</code> to deal with the situation.</p>
<p>The combination of <code>Open()</code> and <code>Read()</code> is easy; however, the combination of <code>Open()</code> to <code>Write()</code> is tricky since the file itself is being modified as writing.</p>
<ul>
<li>Seperate file instances altogether<br>Writes by one process not visible to others.</li>
<li>Seperate file instances until Close()<br>Write visible after Close(), OS decides the merging</li>
<li>Single instance of the file<br>Writes visible immediately to others<blockquote>
<p>In all cases, fp is private.</p>
</blockquote>
</li>
</ul>
<h4 id="NAMING"><a href="#NAMING" class="headerlink" title="NAMING"></a>NAMING</h4><p><strong>Naming primitives</strong><br>Naming &#x3D; mapping : human-redable string -&gt; uid<br>Directory(folder) &#x3D; collection of mappings(namings)</p>
<p><strong>Directory Structure</strong></p>
<ul>
<li>Flat structure</li>
<li>Two-level structure</li>
<li>Hierarchical<br>Hierarchical directory structure can have different shapes(data structure)<br>EXP: tree, acyclic graph(acyclic graph enables short cut creation compared to tree)<blockquote>
<p>Shortcut creation(in Linux): Hard Link &amp; Soft Link<br><strong>Hard Link</strong>: Creates a new mapping of a string to the existing UID<br><strong>Soft Link</strong>: Creats a new mapping of a string to the existing string<br><img src="/.com//4.png" alt="Def"><br><img src="/.com//5.png" alt="Difference"></p>
</blockquote>
</li>
</ul>
<h4 id="LINUX-PRIMITIVES"><a href="#LINUX-PRIMITIVES" class="headerlink" title="LINUX PRIMITIVES"></a>LINUX PRIMITIVES</h4><p>Collapses in a single interface of the previous primitives.</p>
<blockquote>
<p>UID is never visible at the user level!!</p>
</blockquote>
<h3 id="Disks"><a href="#Disks" class="headerlink" title="Disks"></a>Disks</h3><p><img src="/.com//6.png" alt="Structure of DISK"><br>Each platter has two surfaces, each surface has its own tracks; each track has its own sectors.<br>Cylinder: a logical grouping of tracks (same distance from the spindle)<br>Block: multiple sectors make up a block.<br><img src="/.com//61.png" alt="Structure of DISK"><br><img src="/.com//62.png" alt="Structure of DISK"></p>
<h4 id="Disk-Interface"><a href="#Disk-Interface" class="headerlink" title="Disk Interface"></a>Disk Interface</h4><p>Disk interface is accessible by sector only.</p>
<hr>
<blockquote>
<p>For memory management, the CPU can directly access memory. CPU can’t read directly from disk, it must go from OS.</p>
</blockquote>
<h4 id="Disk-Access"><a href="#Disk-Access" class="headerlink" title="Disk Access"></a>Disk Access</h4><ul>
<li>Head Selection: choose the platter to read&#x2F;write</li>
<li>Seek Time: choose the corresponding track</li>
<li>Rotational Latency: point to the corresponding block</li>
<li>Transfer Time: reading or writing to the devixce</li>
<li>Controller Overhead:</li>
</ul>
<p>Seek Time dominates the time complexity.<br>Disk Access time &gt;&gt; Memory access time(nanoseconds)</p>
<table>
<tr><td>Component</td><td>Time</td></tr>
<tr><td>Head Selection</td><td>nanoseconds</td></tr>
<tr><td>Seek Time</td><td>3-12 milliseconds</td></tr>
<tr><td>Rotational Latency</td><td>2-7 milliseconds</td></tr>
<tr><td>Transfer Time</td><td>microseconds</td></tr>
<tr><td>Controller Overhead</td><td> less than 1 millisecond</td></tr>
</table>

<blockquote>
<p>To minimize latency, disk saves the file to the nearest track with priority.<br>When the disk is doing sequential access, the seek and rotational delay only appears once.</p>
</blockquote>
<h4 id="Optimizing-Disk-Access"><a href="#Optimizing-Disk-Access" class="headerlink" title="Optimizing Disk Access"></a>Optimizing Disk Access</h4><p><strong>Rules</strong>:</p>
<ol>
<li><p>Do not access disk, use a cache<br> What? -&gt; Keep currently accessed blocks in memory.<br> Why? -&gt; Reduce latency and disk load<br> How? -&gt; Reserve kernel memory for cache<br> *Cache entries: file blocks (of block size)</p>
<ul>
<li><p><strong>Read with a cache</strong></p>
<ul>
<li>If in cache: return data from cache</li>
<li>If not: find free cache slot -&gt; initial disk read -&gt; when disk read completes, return data</li>
</ul>
</li>
<li><p><strong>Write with a cache</strong></p>
<ul>
<li>writing will always be buffered in memory, so we always writing in the cache</li>
<li>How does it get to disk?<ul>
<li>write through: after writing to the cache, directly write to the disk and then return to the user</li>
<li>write behind: return to the user first then write to the disk<br> <em>(The buffer needs to be flushed into the device at some point later)</em></li>
</ul>
</li>
</ul>
<blockquote>
<p>Response time: write-behind is better<br>Disk Load: write behind is better<br>Crash: write-through is better</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Read ahead and do not wait disk (prefetching)<br>#Only for sequential access<br>What? -&gt; request a block and the next blocks will be read also<br>Why? -&gt; No disk I&#x2F;O on user access to block i+1<br>How? -&gt; Put the next blocks in the buffer cache</p>
</li>
<li><p>Minimize Seeks</p>
<ul>
<li>Clever Disk Allocation<br> <strong>Idea</strong>: locate related data on same cylinder, and allocate <u>related</u>(sequential access &#x2F; consecutive blocks in the same file) blocks <u>together</u>(on the same or nearby cylinder)</li>
<li>Disk Scheduling<br>  <strong>Idea</strong>: reorder requests to seek as little as possible, rearranging the order of file tasks(read&#x2F;write)<ul>
<li>FCFS</li>
<li>SSTF(Shortest Seek Time First)<ul>
<li>Pro: good seek times </li>
<li>Con: Starvation</li>
</ul>
</li>
<li>SCAN<ul>
<li>Seperate the movement in two parts, one continually moving up, another continually moving down</li>
</ul>
</li>
<li>C-SCAN<ul>
<li>always moving in one direction (see class)</li>
</ul>
</li>
<li>C-LOOK<ul>
<li>same as C-SCAN but not going all the way to zero or max of cylinder<blockquote>
<p>Clever disk allocation and disk scheduling are complementary.<br>Low load: clever allocation is better (not many scheduling oppurtunities)<br>High load: disk scheduling is better</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Avoid rotational latency</p>
</li>
</ol>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #ff7d73">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Notes/" style="color: #ffa2c4">
                Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/03/25/COMP310-Intro-to-FileSystems/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/06/COMP310-MemoryManagement-DemandPaging/">
        <h2 class="post-title">COMP310_MemoryManagement:DemandPaging</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/6
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h3 id="Memory-Management-Demand-Paging"><a href="#Memory-Management-Demand-Paging" class="headerlink" title="Memory Management: Demand Paging"></a>Memory Management: Demand Paging</h3><p>For system using right now, most are based on paging instead of segmentation or base&amp;bounds.</p>
<ul>
<li>Base&amp;Bounds &#x3D;&gt; used only for niche</li>
<li>Segmentation &#x3D;&gt; abandoned<ul>
<li>high complexity for little gain</li>
<li>Effect approximated with paging + valid bits</li>
</ul>
</li>
<li>Paging &#x3D;&gt; <strong>universal</strong></li>
</ul>
<p><em><strong>Segmentation can be compacted but hard to manage. Segmentation usually used in embedded development.</strong></em></p>
<h4 id="Paging"><a href="#Paging" class="headerlink" title="Paging"></a><strong>Paging</strong></h4><p><strong>Terminology:</strong><br>  Page: fixed-size portion of virtual memory<br>  Frame: fixed-size portion of physical memory<br>  Page size &#x3D; Frame size<br>  Typical size: 4k-8k (always power of 2)  </p>
<ul>
<li>Virtual address space<br>Linear from 0 up to a multiple of page size</li>
<li>Physical address space<br>Non-contiguous set of frames, one per page</li>
<li>Virtual Address<ul>
<li>Two components in the virtual address :<br>VPN:Virtual page number<br>Offser:offset within the page (page size &#x3D; $2^{offset}$ <strong>Bytes</strong>)</li>
<li><strong>VPN</strong> –(Address Translation(MMU))–&gt;<strong>PFN(Physical Frame Number)</strong></li>
</ul>
</li>
<li>MMU<ul>
<li>Page Table<ul>
<li>Page table is the data structure mapping VPN to PFN.</li>
<li>Each process has a page table. -&gt; each time we do a context switch, the page table needs to be switched also</li>
</ul>
</li>
<li>MMU need a pointer to page table in memory and the length of the page table</li>
</ul>
</li>
</ul>
<h5 id="Advantage-amp-Disadvantage"><a href="#Advantage-amp-Disadvantage" class="headerlink" title="Advantage &amp; Disadvantage"></a><strong>Advantage &amp; Disadvantage</strong></h5><ul>
<li>Advantage: easier to implemented compared to segmentation  with compaction</li>
<li>Disadvantage: <ul>
<li>P1: may have free(null) page &#x3D; sparsely used page may appears &#x3D; internal fragmentation $\Rightarrow$ external fragmentation<br><strong>The severity of this problem depends on the page size</strong></li>
<li>P2: Low translation performance (virtuial address -&gt;page table(in main emory)-&gt;accession(in main memory)) &#x3D; reducing performance by factor of 2</li>
</ul>
</li>
</ul>
<h6 id="Solution-to-P1-valid-x2F-invalid-bit"><a href="#Solution-to-P1-valid-x2F-invalid-bit" class="headerlink" title="Solution to P1: valid&#x2F;invalid bit"></a><strong>Solution to P1: valid&#x2F;invalid bit</strong></h6><p>We can denote the corresponding pages with a valid bit to indicate whether its used or not. (<strong>Used for valid bit, unused for invalid bit</strong>)<br><strong>This actually means the page table itself no longer covers the entire virtual address space(all possible pages in thrtual memory) but the allocated pages by the process.</strong></p>
<h6 id="Solution-to-P2-TLB-Translation-Lookaside-Buffer"><a href="#Solution-to-P2-TLB-Translation-Lookaside-Buffer" class="headerlink" title="Solution to P2: TLB(Translation Lookaside Buffer)"></a><strong>Solution to P2: TLB(Translation Lookaside Buffer)</strong></h6><p>TLB(Translation lookaside buffer) is a part of MMU which makes the map(translation from virtual address(page number) to physical address) fast.  </p>
<p>Part of the page table is in the MMU(TLB). If the map is in it, we get a “hit”, thus no need to find in memory for the map again. If a miss happened, we need to find it in the memory.</p>
<blockquote>
<p>Page Table is stored in main memory and MMU has a pointer to it with the length. TLB is not in main memory but in MMU.</p>
</blockquote>
<blockquote>
<p>Notice that actually finding in memory is by use TLB again.</p>
</blockquote>
<p><img src="/.com//11111.png"><br><img src="/.com//22.png" alt="TLB MISS1"><br><img src="/.com//23.png" alt="TLB MISS2"></p>
<p><strong>The hardware basis of TLB</strong><br>Use <strong>associative memory</strong>(special hardware)  </p>
<ul>
<li>Regular Memory -&gt; lookup by address</li>
<li>Associative Memory -&gt; lookup by contents &amp; lookup in parallel(lookup all at the same time)</li>
</ul>
<p><img src="/.com//01.png" alt="Regular Memory"><br><img src="/.com//02.png" alt="Regular Memory"><br><em>Key &#x3D; Pageno , Value &#x3D; Frameno</em></p>
<p><strong>TLB Size</strong><br>TLB is expensive and small(64-1024 entries)<br>Want TLB hit rate close to 100%<br>If TLB full, need to replace existing entry</p>
<p><strong>TLB Hit Rate and Locality</strong> </p>
<ul>
<li>Temporal Locality -&gt; An instruction that has been accessed will be re-accessed soon in the future</li>
<li>Spatial Locality -&gt; An instruction is accessed, then the instructions near to it will likely soon be accessed<blockquote>
<p>Accession to an array can be both an example to spatial locality and temporal locality</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>They are used together most of the time but may depend.</p>
</blockquote>
<h5 id="Process-Switching-with-TLB"><a href="#Process-Switching-with-TLB" class="headerlink" title="Process Switching with TLB"></a><strong>Process Switching with TLB</strong></h5><h6 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a><strong>Problem</strong></h6><p>Inability to distinguish between pageno of different processes in TLB.<br><img src="/.com//33.png" alt="TLB PROBLEM"></p>
<h6 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a><strong>Solution</strong></h6><ul>
<li>Invalidation of TLB : invalidate all TLB entries(by valid bits) as switching<ul>
<li>Pro: Simply requires one Valid Bit</li>
<li>Con: process switch expensive</li>
<li>Con: new process incurs 100% TLB misses</li>
</ul>
</li>
<li>Process Identifier : add process identifier to TLB entries<ul>
<li>Con: complicated</li>
<li>Pro: cheaper</li>
</ul>
</li>
</ul>
<hr>
<h4 id="Computation-for-the-size-of-TLB"><a href="#Computation-for-the-size-of-TLB" class="headerlink" title="Computation for the size of TLB"></a><strong>Computation for the size of TLB</strong></h4><p><em><strong>Check the lecture</strong></em><br><img src="/.com//44.png" alt="COMPUTATION"></p>
<blockquote>
<p>Explanation:<br>4kB Pages &#x3D;&gt; The <u>number of entries</u> in a <strong>page</strong> is 4kB(4028).<br>Page table entries &#x3D;&gt; number of entries in a <strong>page table</strong><br>Every page table entry &#x3D;&gt; the <strong>size</strong> of each table entry in the main memory</p>
</blockquote>
<h4 id="How-to-make-Page-Table-Smaller"><a href="#How-to-make-Page-Table-Smaller" class="headerlink" title="How to make Page Table Smaller?"></a><strong>How to make Page Table Smaller?</strong></h4><ul>
<li>Big Pages</li>
<li>Segmentation + Paging</li>
<li>Multi-level page tables</li>
</ul>
<h5 id="Big-Pages"><a href="#Big-Pages" class="headerlink" title="Big Pages"></a><strong>Big Pages</strong></h5><p>Advantage: Easy to implement<br>Disadvantage: Larger internal fragmentation<br><em><strong>Most systems use 4KB or 8KB pages in common sense</strong></em></p>
<h5 id="Segmentation-Paging"><a href="#Segmentation-Paging" class="headerlink" title="Segmentation + Paging"></a><strong>Segmentation + Paging</strong></h5><p>Divide address space into segments, than devide each segment into fixed-sized pages.<br>Virtual address divided into three portions:</p>
<table><tr><td>seg</td><td>page number</td><td>page offsers</td></tr></table>

<p>Advantage:  </p>
<ul>
<li>Supports sparse address spaces<ul>
<li>decrease size of page tables</li>
<li>if segment not used, not need for page table</li>
</ul>
</li>
<li>enable sharing</li>
<li>No external fragmentation</li>
</ul>
<p>Disadvantage: </p>
<ul>
<li>each segment <strong>might</strong> have large page table</li>
<li>must allocate each page table contiguously</li>
</ul>
<h5 id="Multi-level-Page-Tables"><a href="#Multi-level-Page-Tables" class="headerlink" title="Multi-level Page Tables"></a><strong>Multi-level Page Tables</strong></h5><p>Turns the linear page table into tree structure. The level is not limited.<br><img src="/.com//55.png"><br><img src="/.com//56.png"></p>
<hr>
<h4 id="Leaving-the-assumption"><a href="#Leaving-the-assumption" class="headerlink" title="Leaving the assumption"></a>Leaving the assumption</h4><p>Previous discussion is based on the assumption that the <strong>whole program</strong> resides in the memory. However, now we are dropping this assumption.</p>
<ul>
<li>Impossible to reside a program in a memory if it’s huge</li>
<li>Only needed pieces need to be resided &lt;&#x3D; load the needed pieces from the file system &#x3D;&gt; many advantages(multiple programs running in a memory&amp;load useful pieces only)</li>
</ul>
<h5 id="Swapping"><a href="#Swapping" class="headerlink" title="Swapping"></a>Swapping</h5><p><strong>Def</strong>:<br> Store the <strong>whole program</strong> temporarily on the disk to get rid of one or more processes.<br><strong>Explanantion</strong>:<br>Processes running on the OS resides on disk; whenever the <strong>scheduler</strong>(context switching) decides one to run, the <strong>whole process</strong> switch into the memory from disk.(also the same for switching out)<br><strong>Disadvantage</strong>:  </p>
<ul>
<li>High latency since need to read from disk(~100million cycles).</li>
<li>Parallelism disabled if the program switching in is huge.<br><strong>Solution</strong>:<br>Demand Paging</li>
</ul>
<h5 id="Demand-Paging"><a href="#Demand-Paging" class="headerlink" title="Demand Paging"></a>Demand Paging</h5><p><strong>Difference with swapping</strong>:  </p>
<ul>
<li>Swapping &#x3D; all of the program is in memory or all of the program is on disk</li>
<li>Demand paging &#x3D; part of program is in memory</li>
</ul>
<p><strong>Reason for use demand paging</strong>:</p>
<ol>
<li>We want to create an illusion for the program that it has a huge memory space(virual memory space &gt;&gt; physical memory space)</li>
<li>Shorter process startup latency<ul>
<li>start process with part of them in memory (Even 1 page suffices)</li>
</ul>
</li>
<li>Better use of main memory<ul>
<li>Enable parellelism of running multiple programs</li>
</ul>
</li>
</ol>
<p><strong>Location of the program</strong>:<br>Part of it is in memory but most of it is on disk(a special partition called <strong>backing store</strong>(<em>only the OS has the access to the backing store</em>)).</p>
<blockquote>
<p>NOTICE: Backing store has all the page information of a program.</p>
</blockquote>
<blockquote>
<p>NOTICE: CPU only directly access memory. CPU access data on disk through OS(OS connect page to the resding backings store).</p>
</blockquote>
<p><strong>High-level Mechanism</strong>:  </p>
<ul>
<li>Page fault:<br>Program needs to access part only on disk</li>
<li>Page fault handling:<br>The process for the OS to handle the page fault: program suspended -&gt; OS runs and gets page from disk -&gt; program is restarted</li>
</ul>
<ol>
<li><p>Discover Page Fault<br>Idea: Using the valid bit in page table</p>
<ul>
<li>With demand paging:<br> <em>(Exception from the following situation raise error of the OS)</em><br> Valid bit &#x3D; 0: page is invalid OR <strong>page is on disk</strong><br> Valid bit &#x3D; 1: page is valid AND <strong>page is in memory</strong><br> (indicates more info needed for the OS (Invalid&#x2F;on-disk?))</li>
</ul>
</li>
<li><p>Suspendisng thne Faulting Process<br>Idea: Trap into the OS</p>
<ul>
<li>invalid bit access generates trap</li>
<li>Process info stored into the PCB and suspend the process(to increas the efficiency of the CPU)<blockquote>
<p>Trapping: Making the switch between the user mode and the kernel mode.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Getting the page from the disk<br>Idea: OS handles fetchs from disk</p>
<ul>
<li><p>Allocate the free frame(if exist) in memory to the process</p>
</li>
<li><p>Find page on disk and transfer the page from disk to frame</p>
<ul>
<li>Two tables are needed here for transferring: Extra table mapping page to backing store</li>
</ul>
</li>
<li><p>While the disk is Busy</p>
<ul>
<li>invoke scheduler to run another process</li>
<li>when disk interrupt arrives, suspend the running process and get back to page default handling</li>
</ul>
</li>
</ul>
</li>
<li><p>Completing page fault handling</p>
<ul>
<li>set the introduced page to valid and assign it a frame number(renew page table)</li>
<li>set process state to ready</li>
<li>invoke scheduler &#x3D;&gt; next time to run will try toaccess the page again</li>
</ul>
</li>
</ol>
<p><img src="/.com//60.png" alt="Demand Paging Summary1"><br><img src="/.com//61.png" alt="Demand Paging Summary2"></p>
<p><strong>How to find a free frame in the main memory?</strong><br>If no free frame available, pick a frame to be replaced -&gt; invalidates its page table entry and TLB entry -&gt; write the frame to disk</p>
<blockquote>
<p>NOTICE: No worry of loosing information by replacing since all pages are stored in backing store.</p>
</blockquote>
<p><strong>How to pick the page&#x2F;frame to replace?(raplacing policies)</strong></p>
<ul>
<li>Random</li>
<li>FIFO</li>
<li>OPT</li>
<li>LRU</li>
</ul>
<p>Goal: minimizing the page fault since they slow down the program</p>
<p><strong>Random</strong> (Relatively universal)<br>Random page is replaced.  </p>
<ul>
<li>PRO: Easy to implement  </li>
<li>CON: Does not take advantage of spatial&#x2F;temporal locality</li>
</ul>
<p><strong>FIFO</strong><br>Oldest page is replaced.(The first one brough into memory)</p>
<ul>
<li>PRO: Easy to implement, Fair</li>
<li>CON: Does not account of “hot” pages</li>
</ul>
<p><strong>OPT(An optimal algorithm)</strong><br>Replace the page that will be referenced the furthest in the future.(OPT insetad of approximated OPT)</p>
<ul>
<li>PRO: Provably optimal</li>
<li>CON: Hard to implement(Can’t predict)<blockquote>
<p>OPT always acts as a basis of comaprison for other algorithms</p>
</blockquote>
</li>
</ul>
<p><strong>LRU(Least Recently Used)</strong><br>Use the past information to predict future usage</p>
<ul>
<li>PRO: Approximate OPT</li>
<li>CON: Hard to implement, does not handle all workloads well<br><img src="/.com//70.png" alt="LRU Hardware Support"></li>
</ul>
<p>是否virtual address包含了在硬盘上的部分而并没有对于物理内存形成一个完全的一一映射？</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #03a9f4">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Note/" style="color: #ff7d73">
                Lecture Note
            </a>
        </span>
        
    </div>
    <a href="/2023/03/06/COMP310-MemoryManagement-DemandPaging/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/05/COMP310-MemoryManagement-VM/">
        <h2 class="post-title">COMP310_MemoryManagement_VM</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/5
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h3 id="Memory-Management-Virtual-Memory"><a href="#Memory-Management-Virtual-Memory" class="headerlink" title="Memory Management: Virtual Memory"></a>Memory Management: Virtual Memory</h3><p>The core conception in memory management is of <strong>address space mapping</strong>.<br>Difference between physical memory and virtual one is: the virtual must be continuous but physical can be fragmental.</p>
<h4 id="Dreamy-Memory"><a href="#Dreamy-Memory" class="headerlink" title="Dreamy Memory"></a><strong>Dreamy Memory</strong></h4><p>The OS tries to make an illusion of using memory of the following properties(desired): <code> private, infinitely large, infinitely fast, nonvolatile, cheap memory</code>.</p>
<h4 id="Memory-Hierarchy"><a href="#Memory-Hierarchy" class="headerlink" title="Memory Hierarchy"></a><strong>Memory Hierarchy</strong></h4><p>However, in real world, the memory follows the hierarchy:</p>
<table>
<tr><th colspan="5"><b>Faster access from left to right, higher price from left to right</b></th></tr>
<tr><td>Registers(1 cycle)</td>
<td>Cache(~10 cycles)</td>
<td>Main Memory(~100 cycles)</td>
<td>Flash Disk(~1M cycles)</td>
<td>Traditional Disk(~10M cycles)</td>
</tr>
<tr><td colspan="3" align="center">Primary Storage</td></tr><tr><td colspan="2" align="center">On CPU</td></tr>
<tr><td colspan="2" align="center">Not cared by OS</td><td colspan="3" align="center">cared by OS(OS memory management)</td></tr>
</table>

<p><em>Cycle here can be interpreted as nano-second(a speed measurement)</em></p>
<h4 id="Goals-of-OS-Memory-Management"><a href="#Goals-of-OS-Memory-Management" class="headerlink" title="Goals of OS Memory Management"></a><strong>Goals of OS Memory Management</strong></h4><p><em>Every access to memory is in virtual instead of physical one, due to the virtual <strong>mapping</strong> by OS.</em></p>
<ol>
<li>Main memory allocation<ul>
<li>location of kernel in address space</li>
<li>what memory to allocate processes</li>
<li>how many processes to allow</li>
</ul>
</li>
<li>Protection(Segeregation)<ul>
<li>no corruption to OS and other processes</li>
<li>Privacy: can’t read data from other processes</li>
</ul>
</li>
<li>Transperancy<ul>
<li>Illusion of private memory for each process</li>
</ul>
</li>
</ol>
<h4 id="Protection"><a href="#Protection" class="headerlink" title="Protection"></a><strong>Protection</strong></h4><p>Protection to be leaded to prevent trespassing access to memory space.<br>The general idea is to add a <strong>check</strong> in the course of accession.</p>
<blockquote>
<p>The <strong>check</strong> is a hardware device (<strong>MMU</strong> Memory Management Unit).</p>
</blockquote>
<h4 id="Transparency"><a href="#Transparency" class="headerlink" title="Transparency"></a><strong>Transparency</strong></h4><p>Essence is to make sure the running of process won’t cause confliction.(no worry of actual running space)</p>
<h4 id="Main-Memory-Allocation"><a href="#Main-Memory-Allocation" class="headerlink" title="Main Memory Allocation"></a><strong>Main Memory Allocation</strong></h4><h5 id="Where-to-allocate-the-kernel"><a href="#Where-to-allocate-the-kernel" class="headerlink" title="Where to allocate the kernel?"></a>Where to allocate the kernel?</h5><p>In the low memory address. The reason is the <strong>interrupt vectors</strong>(the address mapping of hardware device of transferring between user and kernel mode) are in the low memory.</p>
<h5 id="Physical-and-Virtual-Memory"><a href="#Physical-and-Virtual-Memory" class="headerlink" title="Physical and Virtual Memory"></a><strong>Physical and Virtual Memory</strong></h5><p>The early days OS runs only single process at a time which is trusted so no virtual(logical) memory is needed; the process directly access the physical memory.<br>However, if the <u>process is malicious(tresspass into the kernel)</u> or there <u>are multiple processes runs at the sam time</u>, the model won’t work. Thus, logical(virtual) memory is needed.</p>
<ul>
<li>Virtual&#x2F;logical address space &#x3D; what the program thinks is its memory</li>
<li>Physical address space &#x3D; actually is its memory(residing physically)</li>
</ul>
<p>CPU(process) –(<strong>generates virtual address space</strong>)–&gt; MAP(MMU) –(Transfer)–&gt; Memory(Physical Address)</p>
<h5 id="Mapping-Scheme"><a href="#Mapping-Scheme" class="headerlink" title="Mapping Scheme"></a><strong>Mapping Scheme</strong></h5><p><strong>Classification</strong></p>
<ul>
<li>Base and Bounds</li>
<li>Segmentation</li>
<li>Paging</li>
</ul>
<p>For each scheme, we need to understand: <code>physical address space, virtual address space, virtual address, MMU.</code></p>
<h6 id="Base-and-Bounds"><a href="#Base-and-Bounds" class="headerlink" title="Base and Bounds"></a><strong>Base and Bounds</strong></h6><ul>
<li>Virtual Address Space<br>Linear address space: from 0 to MAX  </li>
<li>Physical Address Space<br>Linear address space: from BASE to BOUNDS &#x3D; BASE + MAX<br>MMU</li>
<li>MMU<br>MMU check <strong>relocation register(holds the base value)</strong> and <strong>limit register(holds the bounds value)</strong>. </li>
<li>Free Space Distribution<br>OS will allocate the new process to the <strong>holes(space which is free)</strong>.<br><em>Free list : A list of the range of the physical memory not in use.</em><ul>
<li>Method<ul>
<li>Take first hole bigger than requested</li>
<li>The smallest hole bigger than requested</li>
<li>The largest hole -&gt; tries to eliminate many unusable smallest holes</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>The problem of base and bounds is there may be huge “free space” occupied by the process in the memory that can’t be reallocated <strong>(internal fragmentation problem)</strong>.<br>One solution is to implement by segmentation.</p>
</blockquote>
<h5 id="Segmentation"><a href="#Segmentation" class="headerlink" title="Segmentation"></a><strong>Segmentation</strong></h5><p>In stead of treat one program as a chunk in address space, we segmented it in <strong>three parts: Code, Heap, Stack</strong> which can grow dynamically.</p>
<blockquote>
<p>The segmentation has many ways, the above 3 parts is only one of them.</p>
</blockquote>
<p>Can be treated as multiple base and bounds.</p>
<ul>
<li><p>Virtual Address Space<br>Two-dimensional space with set of segements and each segment ‘i’ is linear from 0 to MAX(i)</p>
</li>
<li><p>Set of segments, each linear</p>
<blockquote>
<p>The order of the segments in physical space has no need to be the same as in virtual address space.</p>
</blockquote>
</li>
<li><p>Virtual Address (Structure)<br><em>Check Lecture</em><br><strong>Segment + Offset</strong><br>–&gt; Number of <strong>segment bits + offset bits</strong> &#x3D; <strong>virtual memory address bits</strong></p>
</li>
<li><p>MMU</p>
<ul>
<li>Segment table<br>Indexed by segment number<br>contains <strong>(base,limit pair)</strong><ul>
<li>base: physical address of segment in memory(where the segment starts)</li>
<li>limit: length of the segment</li>
</ul>
</li>
<li>Pointer to segment table in memory</li>
<li>length of segment table<blockquote>
<p>notice a recursive use in MMU</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h6 id="Advantage-and-Disadvantage"><a href="#Advantage-and-Disadvantage" class="headerlink" title="Advantage and Disadvantage"></a><strong>Advantage and Disadvantage</strong></h6><ul>
<li>Disadvantage<br>Segmentation requires the segmentation table(a data structure) to be stored in MMU, which is convoluted.</li>
<li>Advantage<br>The segmentation table actually enables memory sharing between processes.<br><em><strong>Sharing is not possible with base&amp;bounds but possible with segmentation.</strong></em></li>
</ul>
<h6 id="Memory-Sharing"><a href="#Memory-Sharing" class="headerlink" title="Memory Sharing"></a><strong>Memory Sharing</strong></h6><p>Memory sharing in segementation can be easily reached by having the same point address in the segmentation table.</p>
<p><strong>Protection Bits</strong><br>To guarantee the <strong>protection property of memory allocation of OS</strong> in the course of memory sharing, <strong>protection bits</strong> by <strong>extra hardware support</strong> are needed.<br>Protection bits is a few more bits <strong>per segment</strong> indicating the permission of <strong>read, write,and execute</strong>.</p>
<hr>
<h5 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a><strong>Compaction</strong></h5><p>Compaction is a way to solve fragmentation problems(holes) in the physical memory. It can be used in both base&amp;bounds and segmentation.<br>However, compaction is inefficient:</p>
<ul>
<li>Process needs to be stopped for rearranging</li>
<li>data need to be copied to somewhere</li>
<li>MMU table changed</li>
</ul>
<p>Besides, if a segment is needed to be expanded after compaction, the compaction needs to be restarted again.</p>
<hr>
<blockquote>
<p>NOTICE:<br>  The info of mapping is all stored in MMU.<br> Internal fragmentation only appears in base&amp;bounds since in segmentation the virtual spaces are all occupied. But external fragmentation happens in both.</p>
<p>Internal Fragmentation: can take free space inside the virtual memory space<br>External Fragmentation: there’s holes(free space) in the physical memory</p>
</blockquote>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #00a596">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Notes/" style="color: #ff7d73">
                Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/03/05/COMP310-MemoryManagement-VM/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/04/COMP310-SynchroP/">
        <h2 class="post-title">COMP310_SynchroP</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/4
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h3 id="Synchronization-Primitives-同步原语"><a href="#Synchronization-Primitives-同步原语" class="headerlink" title="Synchronization Primitives 同步原语"></a>Synchronization Primitives 同步原语</h3><h4 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a><strong>Concurrency</strong></h4><h4 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a><strong>Purpose</strong></h4><p>The motivation for leading into concurrency:</p>
<ul>
<li>CPU trend: Same speed, multiple cores &lt;- destined by Moore’s Law</li>
<li>Goal: write applications fully utilize many cores</li>
</ul>
<h5 id="Option"><a href="#Option" class="headerlink" title="Option:"></a><strong>Option:</strong></h5><ul>
<li>Multiprocess<ul>
<li>apps based on many communicating process</li>
<li>communicate through message passing -&gt; no shared memeory</li>
<li>Pros: One process crashing not affect other processes</li>
<li>Cons: High communication overloads &amp; Expensive context switching</li>
</ul>
</li>
<li>Multithread  <ul>
<li>multiple threads in a process</li>
<li>communicate through memory sharing(shared address space)</li>
<li>Pros: High efficiency</li>
<li>Cons: One crash whole crash</li>
</ul>
</li>
</ul>
<h5 id="Non-Determinism"><a href="#Non-Determinism" class="headerlink" title="Non-Determinism:"></a><strong>Non-Determinism:</strong></h5><ul>
<li>Concurrency leads to non-deterministic results -&gt; depends on CPU scheduler<ul>
<li>Different results with same inputs</li>
<li>Race Conditions</li>
</ul>
</li>
</ul>
<h4 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a><strong>Thread</strong></h4><h5 id="Def"><a href="#Def" class="headerlink" title="Def"></a><strong>Def</strong></h5><p>The smallest controllable unit of the OS. The essential part of thread is data(memory) sharing.</p>
<h5 id="Difference-to-Process"><a href="#Difference-to-Process" class="headerlink" title="Difference to Process"></a><strong>Difference to Process</strong></h5><ul>
<li>Processes provide seperation -&gt; suitable for coarse interaction</li>
<li>Threads do not provide seperation -&gt; suitable for tighter integration</li>
</ul>
<h5 id="Shared-Data"><a href="#Shared-Data" class="headerlink" title="Shared Data"></a><strong>Shared Data</strong></h5><ul>
<li>Advantage: Many threads can read&#x2F;write it</li>
<li>Dis: Data racing</li>
</ul>
<h6 id="Dara-Racing"><a href="#Dara-Racing" class="headerlink" title="Dara Racing"></a><strong>Dara Racing</strong></h6><ul>
<li>Unwanted access to shared data</li>
<li>result of interleaving of thread executions</li>
<li>program must be correct for all interleavings</li>
</ul>
<p>Data racing is one of the major causes of non-deterministicity of concurrency.  </p>
<h4 id="Synchronization-Primitives"><a href="#Synchronization-Primitives" class="headerlink" title="Synchronization Primitives:"></a><strong>Synchronization Primitives:</strong></h4><p><em>implemented via hardware support in kernel mode</em></p>
<table><tr><td>Software</td><td>Hardware</td></tr>
<tr><td><ul><li>Monitors</li><li>Semaphores</li><li>Locks(mutex)</li><li>Condition Variables</li></ul></td><td><ul><li>Loads</li><li>Stores</li><li>Test&Set</li><li>Disable Interrupts</li></ul></td></tr></table>

<h5 id="Atomization-Mutual-Exclusion"><a href="#Atomization-Mutual-Exclusion" class="headerlink" title="Atomization(Mutual Exclusion)"></a><strong>Atomization(Mutual Exclusion)</strong></h5><p>The aforementioned problem generates the following basic approach to multithreading with the solution:<br><em>The core is atomization(mutual exclusion of critical section).</em> </p>
<ol>
<li>Divide work among multiple threads</li>
<li>Shared data -&gt; Put shared data access in <u>critical section</u>(<strong>atomization</strong>)</li>
</ol>
<h6 id="Purpose-1"><a href="#Purpose-1" class="headerlink" title="Purpose:"></a><strong>Purpose:</strong></h6><p>Prevents simultaneous access to a shared resource(memory region, …);solving critical section problem.</p>
<p>We need library support(pthreads) to achieve mutual exclusion.  </p>
<blockquote>
<p><strong>POSIX Thread Libraries</strong></p>
<ul>
<li>Thread API for C&#x2F;C++</li>
<li>User-level library:<ul>
<li>#include&lt;pthread.h&gt;</li>
<li>Compile and link with <code>-pthread</code></li>
</ul>
</li>
<li>Support for thread creation, termination, synchronization</li>
</ul>
<p>pthread_create();  pthread_exit(); pthread_join()</p>
</blockquote>
<blockquote>
<p><strong>Pthread_Locks:</strong><br>##Notice that the lock itself is a shared variable<br>Pthread_mutex_lock(mutex)<br><em>If lock is held by another thread, block; otherwise, acquire the lock and proceed.</em><br><em><u>This actually means the condition of the lock is always checking. System resource is in use.</u></em><br>Pthread_mutex_unlock(mutex)<br><em>Release the lock</em></p>
</blockquote>
<h6 id="Deadlocks"><a href="#Deadlocks" class="headerlink" title="Deadlocks"></a><strong>Deadlocks</strong></h6><p>Threads are stuck waiting for blocked resources and no amount of retry will help.</p>
<h5 id="Condition-Variables"><a href="#Condition-Variables" class="headerlink" title="Condition Variables"></a><strong>Condition Variables</strong></h5><p>Conditional Variable is a sychronization primitive which is a bit complex than lock.</p>
<ul>
<li>Used when thread A needs to wait for an event done by thread B</li>
<li>A waits until the certain condition is true<ol>
<li>Test the condition</li>
<li>If the condition is not true, call<br> <code>pthread_cond_wait()</code> -&gt; causes A be blocked until the condition is true</li>
</ol>
</li>
<li>At some point B makes the condition true<ol>
<li>Then B calls <code>pthread_cond_signal()</code> -&gt;unblocks A</li>
</ol>
</li>
</ul>
<blockquote>
<p><em>Condition variable is a shared data, so introduce lock(mutex) here.</em></p>
</blockquote>
<blockquote>
<p><strong>Conditional Variables Interface</strong><br>pthread_cond_init(pthread_cond_t *cv, pthread_condattr_t *cattr)</p>
<ul>
<li>Initialize the conditional variable, cattr can be null</li>
</ul>
<p>pthread_cond_wait(pthread_cond_t *cv, pthread_mutex_t *mutex)</p>
<ul>
<li>Block thread until condition is treu, and automatically unblock mutex</li>
</ul>
<p>pthread_cond_signal(pthread_cond_t *cv)</p>
<ul>
<li>Unblock one thread blocked by the conditional variable at random</li>
</ul>
<p>pthread_cond_broadcast(pthread_cond_t *cv)</p>
<ul>
<li>Unblock all threads blocked by the conditional variable</li>
</ul>
</blockquote>
<h6 id="Advantage"><a href="#Advantage" class="headerlink" title="Advantage"></a><strong>Advantage</strong></h6><p>A waits(sleeps) until a certain condition is true; CPU is not busy(not many resources is used).</p>
<h6 id="Two-Problems-for-Naive-Conditional-Variable-and-the-Solution"><a href="#Two-Problems-for-Naive-Conditional-Variable-and-the-Solution" class="headerlink" title="Two Problems for Naive Conditional Variable and the Solution"></a><strong>Two Problems for Naive Conditional Variable and the Solution</strong></h6><p>Check the lecture.</p>
<h4 id="Semaphores"><a href="#Semaphores" class="headerlink" title="Semaphores"></a><strong>Semaphores</strong></h4><p><em>#include&lt;semaphore.h&gt;</em><br>Semaphore is a shared, non-negative counter with two primary operations: wait(attempts to decrement the counter; blocks when the counter is 0),post&#x2F;signal(attempts to increment the counter).  </p>
<blockquote>
<p>Notice that the increment and decrement in semaphore are atomic.  </p>
</blockquote>
<blockquote>
<p>Semaphore value can be initialized upon creation to a positive value, or 0.</p>
</blockquote>
<h5 id="Uses"><a href="#Uses" class="headerlink" title="Uses"></a><strong>Uses</strong></h5><ul>
<li>Mutual exclusion:<br>A semaphore with its counter initialized to 1 is equivalent to a lock.</li>
<li>Bound the currency<br>Initialized to a larger value to bound the # of threads out of N to proceed.</li>
<li>Consumer-Producer Problem</li>
</ul>
<h5 id="interface"><a href="#interface" class="headerlink" title="interface"></a><strong>interface</strong></h5><blockquote>
<p>int sem_init(sem_t *sem,int pshared, unsigned value)<br>int sem_post(sem_t *sem)<br>int sem_wait(sem_t *sem)  </p>
</blockquote>
<hr>
<h4 id="Hardware-Implementation-of-synchronization"><a href="#Hardware-Implementation-of-synchronization" class="headerlink" title="Hardware Implementation of synchronization"></a><strong>Hardware Implementation of synchronization</strong></h4><h5 id="Problem-Specifications"><a href="#Problem-Specifications" class="headerlink" title="Problem Specifications"></a><strong>Problem Specifications</strong></h5><ul>
<li>Safety(no tresspass of protected space)</li>
<li>Liveness(achieved final goal)</li>
</ul>
<h5 id="Lock-Implementation"><a href="#Lock-Implementation" class="headerlink" title="Lock Implementation"></a><strong>Lock Implementation</strong></h5><p>Check lecture for detailed notes.  </p>
<h6 id="Store-amp-Load"><a href="#Store-amp-Load" class="headerlink" title="Store &amp; Load"></a><strong>Store &amp; Load</strong></h6><p>Treat store as a signaling method to indicate the running status of threads; using load to determine if run or not based on status.<br><em>Disadvantage: busy_waiting</em></p>
<h6 id="Disable-Interrupts"><a href="#Disable-Interrupts" class="headerlink" title="Disable Interrupts"></a><strong>Disable Interrupts</strong></h6><p>Thread uses the syscall of LOCK to disable the interrupter in kernel, renable interrupter after finishing.<br><em>Adv: Compared to store&amp;load, thread can be hypnotized</em></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #ff7d73">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Notes/" style="color: #03a9f4">
                Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/03/04/COMP310-SynchroP/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/03/COMP310-multithreading/">
        <h2 class="post-title">COMP310_multithreading</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/3
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="Multithreading"><a href="#Multithreading" class="headerlink" title="Multithreading"></a><strong>Multithreading</strong></h2><h3 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a><strong>Purpose</strong></h3><p>Still use web server as an example:  </p>
<ol>
<li>to ensure a certain level of security(for example, to guarantee the running code on the server would not disrupt anything), we may use multiprocess since process itself ensures a segregation</li>
<li>if security is guaranteed, multithread can be considered to its efficiency(by shared data)</li>
</ol>
<p><em>Static data tend to be processed by thread, dynamic by process in server.</em></p>
<h3 id="Basic-Approach-to-Multithreading"><a href="#Basic-Approach-to-Multithreading" class="headerlink" title="Basic Approach to Multithreading"></a><strong>Basic Approach to Multithreading</strong></h3><ol>
<li>Divide “work” among multiple threads(based on the property of work per se)</li>
<li>Shared data<ul>
<li>Only <code>global variables</code> and <code>heap</code> can be shared.</li>
<li>shared data accession by critical section</li>
</ul>
</li>
</ol>
<h3 id="Locking"><a href="#Locking" class="headerlink" title="Locking"></a><strong>Locking</strong></h3><p>For example, we may want to have a multithreading program compute the sum and products of elements in two arrays:</p>
<pre><code class="pseudo">main()&#123;
    int i, sum=0, prod=1
    for(i=0;i&lt;MAX_THREADS;i++)&#123;Pthread_create(...)&#125;
    for(i=0;i&lt;MAX_THREADS;i++)&#123;Pthread_join(...)&#125;
    printf(sum)
    printf(prod)
&#125;

Threadcode()&#123;
    int i,c
    for(i=my_min;i&lt;my_max;i++)&#123;
        c = a[i] * b[i]
        sum += c
        prod *= c
    &#125;
&#125;
</code></pre>
<blockquote>
<p><code>htop</code> can be used to check the status of the resources(CPU,memory…) </p>
</blockquote>
<p>We need to implement lock in thread to prevent data racing.<br>The naive way would be to implement biglock:</p>
<pre><code class="pseudo">Threadcode()&#123;
    int i,c
    for(i=my_min;i&lt;my_max;i++)&#123;
        c = a[i] * b[i]
        pthread_mutex_lock(biglock)
        sum += c
        prod *= c
        pthread_mutex_unlock(biglock)
    &#125;
&#125;
</code></pre>
<p>However, it reduces performance since <u>single lock inhibits parallelism</u>. Therefore, two approaches invented to deal with it:  </p>
<ol>
<li>Fine-grain locking:<ul>
<li>Multiple locks on individual pieces of shared data</li>
</ul>
</li>
<li>Privitization<ul>
<li>Make shared data accesses into private data access</li>
</ul>
</li>
</ol>
<h4 id="Fine-Grain-Locking"><a href="#Fine-Grain-Locking" class="headerlink" title="Fine-Grain Locking"></a><strong>Fine-Grain Locking</strong></h4><pre><code class="pseudo">Threadcode()&#123;
    int i,c
    for(i=my_min;i&lt;my_max;i++)&#123;
        c = a[i] * b[i]
        pthread_mutex_lock(sumlock)
        sum += c
        pthread_mutex_unlock(sumlock)
        pthread_mutex_lock(prodlock)
        prod *= c
        pthread_mutex_unlock(prodlock)
    &#125;
&#125;
## 2 lock accesses per thread, per iteration
</code></pre>
<h4 id="Privitization"><a href="#Privitization" class="headerlink" title="Privitization"></a><strong>Privitization</strong></h4><h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea:"></a><strong>Idea:</strong></h5><p>For each thread define the local variables to represent the parts of the global variables; access the loop by the locals. Finally using the lock to the local variables.</p>
<pre><code class="pseudo">Threadcode()&#123;
    int i,c
    local_s =0
    local_p =1
    for(i=my_min;i&lt;my_max;i++)&#123;
        c = a[i] * b[i]
        local_s += c
        local_p *= c
    &#125;
        pthread_mutex_lock(sumlock)
        sum += local_s
        pthread_mutex_unlock(sumlock)
        pthread_mutex_lock(prodlock)
        prod *= local_p
        pthread_mutex_unlock(prodlock)
&#125;
## 2 lock accesses per thread, in total
</code></pre>
<h3 id="Producer-x2F-Consumer-Problem"><a href="#Producer-x2F-Consumer-Problem" class="headerlink" title="Producer&#x2F;Consumer Problem"></a><strong>Producer&#x2F;Consumer Problem</strong></h3><p>Arises when two or more threads communicate with each other.</p>
<h4 id="Def"><a href="#Def" class="headerlink" title="Def:"></a><strong>Def:</strong></h4><p>One shared bounded buffer with N entries. Requirements:  </p>
<ol>
<li>No production when N are all full(harder to deal since info may loss)</li>
<li>No consumption when no entry is full(easy to deal)</li>
<li>Access to the buffer is mutually exclusive(at a time only one process should be able to access the shared buffer and make changes to it)</li>
</ol>
<p><em>Locks cannot deal with it</em></p>
<h4 id="Solution-Semaphores"><a href="#Solution-Semaphores" class="headerlink" title="Solution: Semaphores"></a><strong>Solution: Semaphores</strong></h4><p><em>check the lecture</em></p>
<h5 id="Single-producer-and-consumer"><a href="#Single-producer-and-consumer" class="headerlink" title="Single producer and consumer"></a><strong>Single producer and consumer</strong></h5><p>Requires 2 semaphores:</p>
<ul>
<li>emptyBuffer: initalize to N -&gt; N empty buffers; producer can run N times first</li>
<li>fullBuffer: initialize to 0 -&gt; 0 full buffers; consumer can run 0 times first</li>
</ul>
<h5 id="Multiple-producers-and-consumers"><a href="#Multiple-producers-and-consumers" class="headerlink" title="Multiple producers and consumers"></a><strong>Multiple producers and consumers</strong></h5><hr>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #ffa2c4">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Notes/" style="color: #03a9f4">
                Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/03/03/COMP310-multithreading/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/03/COMP310-multiprocesscom/">
        <h2 class="post-title">COMP310_Multiprocess Communication</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/COMP310/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                COMP310
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/3
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h1 id="Multiprocess-Communication"><a href="#Multiprocess-Communication" class="headerlink" title="Multiprocess Communication"></a>Multiprocess Communication</h1><p><em>Some is not included.</em></p>
<h3 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose:"></a><strong>Purpose</strong>:</h3><p>Most times, the program(shell,compiler…) we have seen right now only represents one process, with the following structure:<br><code>Code, Globals, Heap, Stack, Registers, PC(Program Counter)  </code><br>However, in complicated cases, we may have one program composed of multiple processes(web server).   <em>In web server, the simplist model comprises two processes, one is used for request fetching, another is for local manipulation.</em></p>
<p>Multiprocess is a way to implement <code>concurrency</code>. The major purpose is still to boost the efficiency for using CPU.</p>
<h3 id="Example-of-Web-Server"><a href="#Example-of-Web-Server" class="headerlink" title="Example of Web Server"></a><strong>Example of Web Server</strong></h3><ol>
<li><p>Simplistic Model (Singel Process)<br><em>in single process, scheduler is inactive</em></p>
<pre><code>WebServerProcess&#123;
 forever&#123;
     wait for incoming request #func 1
     read file from disk #
     send file in response # func 2
 &#125;
&#125;
</code></pre>
</li>
<li><p>After Seperation</p>
<pre><code>Listener&#123;
 forever&#123;
     wait for incoming request
     CreateProcess( worker, request ) # activate Worker
 &#125;
&#125;

WorkerProcess(request)&#123;
 read file from disk
 send response
 exit
&#125;
</code></pre>
<p><em>The idea is to create each worker(process) for a corresponding request to enable the scheduler.</em>  </p>
<h4 id="Amount-of-work-on-server-per-request"><a href="#Amount-of-work-on-server-per-request" class="headerlink" title="Amount of work on server per request:"></a><em><strong>Amount of work on server per request:</strong></em></h4><ul>
<li>Receive network packet(request)</li>
<li>Run listner process</li>
<li>Create worker process -&gt; <em>which can be expensive</em></li>
<li>Read file from disk</li>
<li>Send response</li>
</ul>
<p> To solve the creation cost, we can do preprocess( create some(max) workers as initialization ).</p>
<pre><code>Listener&#123;
    for(i=0; i&lt;MAX_PROCESSES; i++) process[i] = CreateProcess(worker)
forever&#123;
    wait for incoming request
    send(request, process[?]) # use Worker
&#125;
&#125;

WorkerProcess[?]&#123;
forever&#123;
wait for message(&amp;request)
read file from disk
send response
exit
&#125;
&#125;
</code></pre>
</li>
</ol>
<h3 id="IPC-Inter-Process-Communication"><a href="#IPC-Inter-Process-Communication" class="headerlink" title="IPC(Inter Process Communication)"></a><strong>IPC(Inter Process Communication)</strong></h3><h4 id="Purpose-1"><a href="#Purpose-1" class="headerlink" title="Purpose:"></a><strong>Purpose</strong>:</h4><p>To communicate the info between processes.</p>
<p>Two ways to implement IPC:</p>
<ul>
<li>message passing<ul>
<li>By value communication</li>
<li>Never by reference -&gt; seperation of msg in sender and receiver</li>
</ul>
</li>
<li>RPC(remote procedural calls)</li>
</ul>
<p>In Web Server, the IPC is implemented in two fields: inside field(communication between worker and listner) and outside field(communication between client and server).<br><em><strong>notice:</strong><br>in web server, the msg passing is not passed by reference but a new copy created instead. (Indicating memory is not shared)<br>in OS, the msg passing is implemented through the kernel.</em></p>
<h4 id="Message-Passing"><a href="#Message-Passing" class="headerlink" title="Message Passing"></a><strong>Message Passing</strong></h4><p>Ways to implement message passing:  </p>
<ul>
<li>Symmetric Addressing</li>
<li>Asymmetric Addressing</li>
<li>Blocking Receive</li>
<li>Nonblocking Receive</li>
</ul>
<p> <em>Example of asymmetric addressing:</em></p>
<pre><code>  Listener&#123;
      for(i=0; i&lt;MAX_PROCESSES; i++) process[i] = CreateProcess(worker)
  forever&#123;
      client_pid = receive(msg) #receive from any client(always asymmetric)
      msg&#39; = modified msg including client_pid
      send (msg&#39;, worker_process[?])
  &#125;
 &#125;

 WorkerProcess[?]&#123;
  forever&#123;
  receive(msg)
  read file from disk
  send (response, client_pid)
  &#125;
 &#125;
</code></pre>
<p><em>More examples please refer to the lecture</em></p>
<h4 id="RPC-Remote-Procedural-Call"><a href="#RPC-Remote-Procedural-Call" class="headerlink" title="RPC(Remote Procedural Call)"></a><strong>RPC(Remote Procedural Call)</strong></h4><p><code>RPC is based on message passing</code></p>
<h5 id="Purpose-2"><a href="#Purpose-2" class="headerlink" title="Purpose"></a><strong>Purpose</strong></h5><p>causes a procedure(function) to execute in a different address space(commonly another computer on a shared network).</p>
<h5 id="RPC-Interface"><a href="#RPC-Interface" class="headerlink" title="RPC Interface"></a><strong>RPC Interface</strong></h5><p>RPC Interface exposes a list of remotely callable procedures, with their signatures(arguments and return values).<br><em><strong><small>Analogy:</small></strong><br>RPC Server &lt;-&gt; Export file system<br>RPC Client &lt;-&gt; Import file system</em><br><em><strong><small>Problem:</small></strong><br>Message passing $\neq$ procedural call</em><br>So How to bridge the gap?<br>Solution: <code>stub library</code></p>
<h5 id="Stub-Library"><a href="#Stub-Library" class="headerlink" title="Stub Library"></a><strong>Stub Library</strong></h5><p><em>client and server stub are generated automatically, and they are part of the application</em>  </p>
<h6 id="Two-message-types"><a href="#Two-message-types" class="headerlink" title="Two message types:"></a><strong>Two message types:</strong></h6><ul>
<li>Call message<ul>
<li>from client to server</li>
<li>contains argument</li>
</ul>
</li>
<li>Return message<ul>
<li>from server to client</li>
<li>contains return values</li>
</ul>
</li>
</ul>
<h6 id="Mechanism"><a href="#Mechanism" class="headerlink" title="Mechanism:"></a><strong>Mechanism:</strong></h6><p>Client process communicate with server process through RPC interface(which implementing stub library, the stubs are generated automatically through the <code>compiler</code>).</p>
<ol>
<li>Clinet proc call clinet stub</li>
<li>client stub goes to kernel and pass the call message</li>
<li>server stub receive from kernel</li>
<li>server get proc call and execute</li>
</ol>
<h6 id="Message-Format"><a href="#Message-Format" class="headerlink" title="Message Format:"></a><strong>Message Format:</strong></h6><p>Message needs to include not only the basic arguments(pid,arg0,…) but which procedure is called.</p>
<blockquote>
<p><strong>Notice</strong><br>The mechanism of RPC indicates it’s very inefficient to implement it. SO CAREFUL THINKING BEFORE IMPLEMENT IT.</p>
</blockquote>
<h4 id="How-does-this-work"><a href="#How-does-this-work" class="headerlink" title="How does this work?"></a><strong>How does this work?</strong></h4><p>Automatic stub generation:</p>
<ul>
<li>rpcbind<br>universal addresses to RPC program number mapper <pre><code>sudo apt_get install rpcbind
</code></pre>
</li>
<li>rpcgen<br>tool generating remote program interface modules</li>
</ul>
<h3 id="IPC-x2F-LPC-x2F-RPC"><a href="#IPC-x2F-LPC-x2F-RPC" class="headerlink" title="IPC&#x2F;LPC&#x2F;RPC"></a>IPC&#x2F;LPC&#x2F;RPC</h3><p>Reference: <a target="_blank" rel="noopener" href="https://blog.csdn.net/Cmm_CSDN/article/details/86138330">https://blog.csdn.net/Cmm_CSDN/article/details/86138330</a><br><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1690556">https://cloud.tencent.com/developer/article/1690556</a></p>
<p>进程通信：</p>
<p>每个进程各自有不同的用户地址空间,<strong>任何一个进程的全局变量在另一个进程中都看不到</strong>，所以进程之间要<strong>交换数据必须通过内核,在内核中开辟一块缓冲区,进程A把数据从用户空间拷到内核缓冲区,进程B再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信。</strong></p>
<p>进程间通信（IPC，Inter-Process Communication）：<br><strong>IPC（进程间通信）是指在操作系统中，不同进程之间进行通信和同步的机制。</strong><br>特指至少两个进程间传送数据或信号的一些技术或方法。进程是操作系统分配资源的最小单位。每个进程都有自己的一部分独立的系统资源，彼此是隔离的。<strong>为了能使不同的进程互相访问资源并进行协调工作</strong>，才有了进程间通信。<strong>这些进程可以运行在同一计算机上或网络连接的不同计算机上</strong>。进程间通信技术包括消息传递、同步、共享内存和远程过程调用。 IPC是一种标准的Unix通信机制。</p>
<p>有三种主要类型的进程间通信（IPC）：  </p>
<ol>
<li>Message passing<br>消息传递（Message Passing）是一种进程间通信（IPC）机制，它允许进程在不共享相同地址空间的情况下进行通信和同步。它通过发送和接收消息来实现。</li>
<li>远程过程调用（RPC  Reomote Procedure Call）：<br>特指一种隐藏了过程调用时实际通信细节的IPC方法。客户端将调用一个本地方法，而这个本地方法则是负责透明的与远程服务端进行过程间通信。这个本地方法会讲相关参数顺序打包到一个消息中，然后把这个消息发送给服务端提供的方法，服务端的方法会从消息中解出序列化发出来的参数，然后执行，最后仍以同样的方式将方法的返回值发送给客户端</li>
<li>共享内存</li>
</ol>
<p>RPC和MP：<br>本质上，RPC是基于message passing基础之上衍生出来的。这两者之间最核心的区别在于RPC的适用点主要是用于远程过程或函数调用；因此，在消除RPC的函数或过程调用功能后，RPC便和message passing没有本质区别。</p>
<p>LPC：<br>LPC（本地过程调用）是<strong>Windows操作系统中的</strong>一种消息传递机制，用于<strong>同一台计算机</strong>上的两个进程之间的通信。它类似于广泛使用的标准远程过程调用（RPC）机制，但<strong>针对Windows进行了优化</strong>。</p>
<p>LPC与消息传递之间的区别：  </p>
<ol>
<li>应用范围：LPC仅用于Windows操作系统中，而消息传递是一种通用的IPC机制。</li>
<li>优化：LPC针对Windows进行了优化，以提高在同一台计算机上的两个进程之间进行通信的效率。</li>
<li>使用方式：LPC不直接通过Windows API提供，而是作为仅供Windows操作系统组件使用的内部机制。而消息传递则可以通过多种编程语言和平台提供的API直接使用。</li>
</ol>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/COMP310/" style="color: #00bcd4">
                COMP310
            </a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/Lecture-Notes/" style="color: #ff7d73">
                Lecture Notes
            </a>
        </span>
        
    </div>
    <a href="/2023/03/03/COMP310-multiprocesscom/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/03/01/Markdown-Guide/">
        <h2 class="post-title">Markdown Guide</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/Guide/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                Guide
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/3/1
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            
            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/Markdown/" style="color: #ffa2c4">
                Markdown
            </a>
        </span>
        
    </div>
    <a href="/2023/03/01/Markdown-Guide/" class="go-post">阅读全文</a>
</div>


            <div class="page-current">
    <div class="prev">
        
    </div>
    <div class="page-index">
        
        <span class="current">1</span>
        
        <span>
            <a class="page-num" href="/page/2/">2</a>
            
            
        </span>
        
    </div>
    <div class="next">
        
        <a class="page-num" href="/page/2/">
            <i class="fa-solid fa-caret-right fa-fw"></i>
        </a>
        
    </div>
</div>

        </div>
    </div>
    
    <div id="home-card">
        <div id="card-div">
    <div class="card-style" style="width: 300px">
        <div class="avatar">
            <img src="/images/OIP.jpg" alt="avatar">
        </div>
        <div class="name">Terrance</div>
        <div class="description">
            <p>Honor Mathematics &amp; Honor Econ &amp; Honor CS</p>

        </div>
        
        
    </div>
</div>

    </div>
    
</div>

                <footer id="footer">
    <div class="footer-wrap">
        <div>
            &copy;
            2023 - 2023 Aubade_Blog
            <span class="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Terrance
        </div>
        <div>Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp; <a target="_blank" rel="noopener" href="https://github.com/argvchs/hexo-theme-particlex">ParticleX Theme</a></div>
        
    </div>
</footer>

            </div>
            </transition>
            <div id="showimg">
                <img id="showimg-content">
            </div>
        </div>
        <script src="/js/functions.js"></script>
<script src="/js/particlex.js"></script>


    </body>
</html>
